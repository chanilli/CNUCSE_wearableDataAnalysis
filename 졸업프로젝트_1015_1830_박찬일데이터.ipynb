{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC=pd.read_csv('1571132161_A013E1\\ACC.csv')\n",
    "BVP=pd.read_csv('1571132161_A013E1\\BVP.csv') ##Blood Volume Pulse\n",
    "EDA=pd.read_csv('1571132161_A013E1\\EDA.csv')\n",
    "HR=pd.read_csv('1571132161_A013E1\\HR.csv')\n",
    "IBI=pd.read_csv('1571132161_A013E1\\IBI.csv') #inter-beat-interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=BVP.loc[::64]\n",
    "b=ACC.loc[::32]\n",
    "c=EDA.loc[::4]\n",
    "a=a.reset_index()\n",
    "b=b.reset_index()\n",
    "c=c.reset_index()\n",
    "DataSet=pd.DataFrame(columns=['BVP','ACC','EDA','HR','EM1','EM2'])\n",
    "DataSet['BVP'] = a.iloc[:,1]\n",
    "DataSet['ACC'] = b.iloc[:,1]\n",
    "DataSet['EDA'] = c.iloc[:,1]\n",
    "DataSet['HR']=HR\n",
    "DataSet=DataSet.drop(DataSet.index[len(HR):len(DataSet)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PCI\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "DataSet['EM1'].iloc[0:int(len(DataSet)/3)]= 0\n",
    "DataSet['EM2'].iloc[0:int(len(DataSet)/3)]= -1\n",
    "DataSet['EM1'].iloc[int(len(DataSet)/3):2*int(len(DataSet)/3)]= 2\n",
    "DataSet['EM2'].iloc[int(len(DataSet)/3):2*int(len(DataSet)/3)]= -2\n",
    "DataSet['EM1'].iloc[2*int(len(DataSet)/3):int(len(DataSet))]= 4\n",
    "DataSet['EM2'].iloc[2*int(len(DataSet)/3):int(len(DataSet))]= -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataSet.to_csv('Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BVP</th>\n",
       "      <th>ACC</th>\n",
       "      <th>EDA</th>\n",
       "      <th>HR</th>\n",
       "      <th>EM1</th>\n",
       "      <th>EM2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64.00</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.71</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.039712</td>\n",
       "      <td>86.00</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>148.81</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.008967</td>\n",
       "      <td>97.00</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.23</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.008967</td>\n",
       "      <td>93.00</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47.26</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.017934</td>\n",
       "      <td>84.25</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      BVP   ACC       EDA     HR  EM1  EM2\n",
       "0   64.00  32.0  4.000000   1.00    0   -1\n",
       "1   85.71  38.0  0.039712  86.00    0   -1\n",
       "2  148.81  44.0  0.008967  97.00    0   -1\n",
       "3   11.23  23.0  0.008967  93.00    0   -1\n",
       "4   47.26  17.0  0.017934  84.25    0   -1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential # 케라스의 Sequential()을 임포트\n",
    "from keras.layers import Dense # 케라스의 Dense()를 임포트\n",
    "from keras import optimizers # 케라스의 옵티마이저를 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(columns=['BVP','ACC','EDA','HR'])\n",
    "df['BVP']=DataSet['BVP']\n",
    "df['ACC']=DataSet['ACC']\n",
    "df['EDA']=DataSet['EDA']\n",
    "df['HR']=DataSet['HR']\n",
    "\n",
    "df_em1=pd.DataFrame(columns=['EM1'])\n",
    "df_em2=pd.DataFrame(columns=['EM2'])\n",
    "df_em1['EM1']=DataSet['EM1']\n",
    "df_em2['EM2']=DataSet['EM2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df_em1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PCI\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder =  LabelEncoder()\n",
    "y1 = encoder.fit_transform(y)\n",
    "Y = pd.get_dummies(y1).values\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((712, 4), (179, 4), (712, 3), (179, 3))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2,random_state=1) \n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                320       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 4,675\n",
      "Trainable params: 4,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "sgd=optimizers.SGD(lr=0.01)\n",
    "model.add(Dense(64,input_shape=(4,),activation='relu'))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4472 - acc: 0.8118 - val_loss: 0.7726 - val_acc: 0.7207\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4693 - acc: 0.8076 - val_loss: 0.7401 - val_acc: 0.7486\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4390 - acc: 0.8272 - val_loss: 0.7999 - val_acc: 0.7486\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4578 - acc: 0.8146 - val_loss: 0.7568 - val_acc: 0.6927\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4414 - acc: 0.8315 - val_loss: 0.8122 - val_acc: 0.7318\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4283 - acc: 0.8329 - val_loss: 0.7252 - val_acc: 0.7430\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4080 - acc: 0.8441 - val_loss: 0.7570 - val_acc: 0.7654\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4224 - acc: 0.8272 - val_loss: 0.8433 - val_acc: 0.7486\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4211 - acc: 0.8244 - val_loss: 0.8198 - val_acc: 0.7542\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4466 - acc: 0.8076 - val_loss: 0.8236 - val_acc: 0.6816\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4691 - acc: 0.8048 - val_loss: 0.7810 - val_acc: 0.7039\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4300 - acc: 0.8230 - val_loss: 0.7753 - val_acc: 0.7430\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4247 - acc: 0.8301 - val_loss: 0.7452 - val_acc: 0.7430\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.3989 - acc: 0.8385 - val_loss: 0.8726 - val_acc: 0.7039\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4432 - acc: 0.8104 - val_loss: 0.8461 - val_acc: 0.7263\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4691 - acc: 0.7992 - val_loss: 0.7979 - val_acc: 0.7263\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4069 - acc: 0.8258 - val_loss: 0.8862 - val_acc: 0.7598\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.3996 - acc: 0.8469 - val_loss: 0.8422 - val_acc: 0.7709\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.3913 - acc: 0.8483 - val_loss: 0.7782 - val_acc: 0.7821\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.3859 - acc: 0.8455 - val_loss: 0.7212 - val_acc: 0.7821\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4059 - acc: 0.8441 - val_loss: 0.8557 - val_acc: 0.7263\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4434 - acc: 0.8216 - val_loss: 0.7140 - val_acc: 0.7821\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.3767 - acc: 0.8553 - val_loss: 0.7872 - val_acc: 0.7654\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.3787 - acc: 0.8413 - val_loss: 0.7476 - val_acc: 0.7821\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.4027 - acc: 0.8371 - val_loss: 0.7950 - val_acc: 0.7430\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.4103 - acc: 0.8357 - val_loss: 0.8165 - val_acc: 0.7542\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4211 - acc: 0.8287 - val_loss: 0.8152 - val_acc: 0.7709\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4147 - acc: 0.8357 - val_loss: 0.7912 - val_acc: 0.7430\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4311 - acc: 0.8272 - val_loss: 0.6833 - val_acc: 0.8101\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.3989 - acc: 0.8413 - val_loss: 0.6454 - val_acc: 0.8045\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.3886 - acc: 0.8469 - val_loss: 0.7427 - val_acc: 0.7486\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4091 - acc: 0.8230 - val_loss: 0.6997 - val_acc: 0.7654\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.3644 - acc: 0.8497 - val_loss: 0.6436 - val_acc: 0.7821\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.3755 - acc: 0.8511 - val_loss: 1.1109 - val_acc: 0.5587\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4428 - acc: 0.8006 - val_loss: 0.8235 - val_acc: 0.7207\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4672 - acc: 0.8048 - val_loss: 0.7358 - val_acc: 0.7430\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4173 - acc: 0.8272 - val_loss: 0.7096 - val_acc: 0.7765\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4280 - acc: 0.8216 - val_loss: 0.7737 - val_acc: 0.7598\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.4307 - acc: 0.8230 - val_loss: 0.6667 - val_acc: 0.8045\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4179 - acc: 0.8132 - val_loss: 0.6749 - val_acc: 0.7765\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.3946 - acc: 0.8511 - val_loss: 0.7019 - val_acc: 0.7877\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.3962 - acc: 0.8357 - val_loss: 0.6811 - val_acc: 0.7765\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.3670 - acc: 0.8511 - val_loss: 0.6230 - val_acc: 0.8045\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.3491 - acc: 0.8581 - val_loss: 0.6781 - val_acc: 0.7654\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.3567 - acc: 0.8624 - val_loss: 0.6394 - val_acc: 0.8045\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.3660 - acc: 0.8413 - val_loss: 0.6827 - val_acc: 0.7989\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.3723 - acc: 0.8539 - val_loss: 0.6305 - val_acc: 0.7821\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.3439 - acc: 0.8624 - val_loss: 0.7030 - val_acc: 0.7486\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.3510 - acc: 0.8483 - val_loss: 0.6370 - val_acc: 0.7877\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.3469 - acc: 0.8497 - val_loss: 0.6848 - val_acc: 0.7374\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.3684 - acc: 0.8455 - val_loss: 0.7499 - val_acc: 0.7709\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.3496 - acc: 0.8652 - val_loss: 0.6957 - val_acc: 0.7821\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.3651 - acc: 0.8441 - val_loss: 0.6587 - val_acc: 0.8156\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.3704 - acc: 0.8385 - val_loss: 0.8349 - val_acc: 0.7263\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.3682 - acc: 0.854 - 0s 100us/step - loss: 0.3790 - acc: 0.8483 - val_loss: 0.6336 - val_acc: 0.7877\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.3455 - acc: 0.8596 - val_loss: 0.6404 - val_acc: 0.7598\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.3468 - acc: 0.8553 - val_loss: 0.7542 - val_acc: 0.7542\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.3609 - acc: 0.8567 - val_loss: 0.7211 - val_acc: 0.7430\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.3735 - acc: 0.8539 - val_loss: 0.6878 - val_acc: 0.7877\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.3477 - acc: 0.8596 - val_loss: 0.6472 - val_acc: 0.7933\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 74us/step - loss: 0.3369 - acc: 0.8624 - val_loss: 0.6443 - val_acc: 0.7877\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.3696 - acc: 0.8638 - val_loss: 0.6332 - val_acc: 0.7933\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.3404 - acc: 0.8624 - val_loss: 0.6135 - val_acc: 0.7765\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.3582 - acc: 0.8413 - val_loss: 0.6564 - val_acc: 0.7933\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.3323 - acc: 0.8610 - val_loss: 0.6753 - val_acc: 0.7877\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.3364 - acc: 0.8596 - val_loss: 0.6830 - val_acc: 0.7709\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.3472 - acc: 0.8638 - val_loss: 0.6473 - val_acc: 0.7598\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.3929 - acc: 0.8118 - val_loss: 0.7500 - val_acc: 0.7598\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.3695 - acc: 0.8385 - val_loss: 0.6514 - val_acc: 0.8101\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.3784 - acc: 0.8539 - val_loss: 0.9149 - val_acc: 0.7486\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.3728 - acc: 0.8539 - val_loss: 0.8817 - val_acc: 0.7207\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.3783 - acc: 0.8469 - val_loss: 0.8208 - val_acc: 0.7542\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4097 - acc: 0.8329 - val_loss: 0.6479 - val_acc: 0.7654\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.3656 - acc: 0.8329 - val_loss: 0.6246 - val_acc: 0.7765\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.3480 - acc: 0.8553 - val_loss: 0.6585 - val_acc: 0.7318\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.3412 - acc: 0.8652 - val_loss: 0.6986 - val_acc: 0.7821\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.3249 - acc: 0.8624 - val_loss: 0.6663 - val_acc: 0.8156\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.3146 - acc: 0.8736 - val_loss: 0.6720 - val_acc: 0.7877\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.3200 - acc: 0.8750 - val_loss: 0.6824 - val_acc: 0.7654\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.3379 - acc: 0.8652 - val_loss: 0.6687 - val_acc: 0.7765\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.3099 - acc: 0.8848 - val_loss: 0.7025 - val_acc: 0.7989\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.3132 - acc: 0.8680 - val_loss: 0.6941 - val_acc: 0.7598\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.3097 - acc: 0.8722 - val_loss: 0.7060 - val_acc: 0.7598\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.3143 - acc: 0.8708 - val_loss: 0.6235 - val_acc: 0.7598\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.3222 - acc: 0.8624 - val_loss: 0.6304 - val_acc: 0.7933\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.3095 - acc: 0.8778 - val_loss: 0.7300 - val_acc: 0.7709\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.3181 - acc: 0.8806 - val_loss: 0.6993 - val_acc: 0.7318\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.3482 - acc: 0.8638 - val_loss: 0.6700 - val_acc: 0.7877\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.3159 - acc: 0.8680 - val_loss: 0.6419 - val_acc: 0.8156\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.3137 - acc: 0.8722 - val_loss: 0.7496 - val_acc: 0.7318\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.3073 - acc: 0.8806 - val_loss: 0.8589 - val_acc: 0.7877\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.3696 - acc: 0.8553 - val_loss: 0.7915 - val_acc: 0.7151\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.3717 - acc: 0.8343 - val_loss: 0.8300 - val_acc: 0.7318\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.3470 - acc: 0.8553 - val_loss: 0.6109 - val_acc: 0.7877\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.2967 - acc: 0.8792 - val_loss: 0.8479 - val_acc: 0.7374\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.3228 - acc: 0.8694 - val_loss: 0.5937 - val_acc: 0.8380\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.2963 - acc: 0.8834 - val_loss: 0.7834 - val_acc: 0.7821\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.3328 - acc: 0.8567 - val_loss: 0.6392 - val_acc: 0.7654\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.2961 - acc: 0.8848 - val_loss: 0.7219 - val_acc: 0.7765\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.3227 - acc: 0.8694 - val_loss: 0.9156 - val_acc: 0.7151\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/179 [==============================] - 0s 50us/step\n",
      "Accuracy = 0.72\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy = {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.63      0.65        59\n",
      "           1       0.60      0.53      0.57        49\n",
      "           2       0.72      0.83      0.77        71\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       179\n",
      "   macro avg       0.67      0.66      0.66       179\n",
      "weighted avg       0.68      0.68      0.68       179\n",
      "\n",
      "[[37 11 11]\n",
      " [11 26 12]\n",
      " [ 6  6 59]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_test_class = np.argmax(y_test,axis=1)\n",
    "y_pred_class = np.argmax(y_pred,axis=1)\n",
    "\n",
    "print(classification_report(y_test_class,y_pred_class))\n",
    "print(confusion_matrix(y_test_class,y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
